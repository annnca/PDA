// MPITest.cpp : Defines the entry point for the console application.
// https://blogs.technet.microsoft.com/windowshpc/2015/02/02/how-to-compile-and-run-a-simple-ms-mpi-program/
//http://xoax.net/cpp/crs/visualcpp/lessons/CreateExe/


#include "stdafx.h"
#include "stdio.h"
#include "stdlib.h"
#include "mpi.h"


/*int main(int argc, char **argv)
{
	int ierr;

	ierr = MPI_Init(&argc, &argv);
	printf("Hello world\n");

	ierr = MPI_Finalize();
}*/

/*
B
the (send or receive) buffer is available for reuse. 
To reuse the buffer, it's sufficient to copy the information to 
another memory area, i.e the library can copy the buffer data to 
own memory location in the library and then, say for e.g,
MPI_Send can return.
NB
the application creates a request for communication for send 
and / or receive and gets back a handle and then terminates. */


/*int main(int argc, char **argv)
{
	int ierr, num_procs, my_id, len;
	char hostname[MPI_MAX_PROCESSOR_NAME];

	//initialize MPI environment
	ierr = MPI_Init(&argc, &argv);

	if (ierr != MPI_SUCCESS) {
		printf("Error starting MPI Program.Terminating.\n");
		MPI_Abort(MPI_COMM_WORLD, ierr);
	}

	// find out MY process ID, and how many processes were started. 
	//MPI_COMM_WORLD is a predefined communicator that includes all the processes in the MPI
	//Environment.
	ierr = MPI_Comm_rank(MPI_COMM_WORLD, &my_id);
	ierr = MPI_Comm_size(MPI_COMM_WORLD, &num_procs);
	MPI_Get_processor_name(hostname, &len);


	printf("Number of tasks= %d My rank= %d Running on %s\n", num_procs, my_id, hostname);

	ierr = MPI_Finalize();
}*/


//blocking send
//int MPI_Send(void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)
//int MPI_Recv(void *buf, int count, MPI_Datatype datatype, int source, int tag,MPI_Comm comm, MPI_Status *status)
//count = size(no of elements) of the buffer tobe sent/received
//datatype = 
//dest – the rank of the receiver processes
//source – the rank of the source process. MPI_ANY_SOURCE allows receiving a message regardless
//of its source
//tag – the message tag. This can be any non-negative integer. Send/Receive perform matching on the
//tag.MPI_ANY_TAG can be used to receive a message regardless of its tag.
//comm – the MPI communicator to be used
//status – structure that indicates the source and tag of the message.
/*#define MASTER	0
int main(int argc, char *argv[]) {
	int numprocs, procid, len;
	char hostname[MPI_MAX_PROCESSOR_NAME];
	int partner, message;
	MPI_Status status;

	MPI_Init(&argc, &argv);

	MPI_Comm_size(MPI_COMM_WORLD, &numprocs);
	MPI_Comm_rank(MPI_COMM_WORLD, &procid);
	MPI_Get_processor_name(hostname, &len);
	printf("Hello from proc %d on %s!\n", procid, hostname);
	if (procid == MASTER) {
		printf("MASTER: Number of MPI procs is : %d\n", numprocs);
	}

	//determine partner and then send /receive with partner
	if (procid < numprocs / 2) {
		partner = numprocs / 2 + procid;
		MPI_Send(&procid, 1, MPI_INT, partner, 1, MPI_COMM_WORLD);
		MPI_Recv(&message, 1, MPI_INT, partner, 1, MPI_COMM_WORLD, &status);
	}
	else {
		if (procid >= numprocs / 2) {
			partner = procid - numprocs / 2;
			MPI_Recv(&message, 1, MPI_INT, partner, 1, MPI_COMM_WORLD, &status);
			MPI_Send(&procid, 1, MPI_INT, partner, 1, MPI_COMM_WORLD);
		}
	}
	//print partner info and exit
	printf("Proc %d is partner with %d\n", procid, message);

	MPI_Finalize();
}*/

/*#define MASTER	0
int main(int argc, char *argv[]) {
	int numprocs, procid, len;
	char hostname[MPI_MAX_PROCESSOR_NAME];
	int partner, message;
	MPI_Status status;
	//request – non-blocking operations are being assigned a request handle returned through this parameter.
	//This handle can be used in wait operations.
	MPI_Request reqs[2];

	MPI_Init(&argc, &argv);

	MPI_Comm_size(MPI_COMM_WORLD, &numprocs);
	MPI_Comm_rank(MPI_COMM_WORLD, &procid);
	MPI_Get_processor_name(hostname, &len);
	printf("Hello from proc %d on %s!\n", procid, hostname);
	if (procid == MASTER) {
		printf("MASTER: Number of MPI procs is : %d\n", numprocs);
	}

	//determine partner and then send /receive with partner
	if (procid < numprocs / 2) {
		partner = numprocs / 2 + procid;
	}
	else {
		if (procid >= numprocs / 2) {
			partner = procid - numprocs / 2;
		}
	}

	MPI_Irecv(&message, 1, MPI_INT, partner, 1, MPI_COMM_WORLD, &reqs[0]);
	MPI_Isend(&procid, 1, MPI_INT, partner, 1, MPI_COMM_WORLD, &reqs[1]);

	//now block until requests are complete
	MPI_Waitall(2, reqs, &status);

	//print partner info and exit
	printf("Proc %d is partner with %d\n", procid, message);

	MPI_Finalize();
}*/
/*MPI Send specifies that a message containing count elements of a specified
datatype starting at address buf is to be sent using the message tag tag to the
process ranked dest in the communicator comm. MPI Send will not return until
it can use send buffer*/

/*MPI Recv blocks a process until it receives a message from the process
ranked source in the communicator comm with message tag tag. Wild cards
MPI ANY SOURCE and MPI ANY FLAG can be used to receive messages. If a wild
card is used, the returned status can be used to determine the actual source
and tag. The recieved message is placed in a receive buffer, which consists
of the storage containing count consecutive elements of the type specified by
datatype, starting at address buf. The length of the received m*/
//A communicator handle defines which processes a particular command will apply to.

#define N		1000
#define MASTER	0

int array[N];
int local_array[N];

int main(int argc, char* argv[]) {
	int proc_id, no_of_procs;
	MPI_Status status;
	int total_sum, partial_sum;
	int i, no_of_elements, id, no_of_elem_for_child, step, sender, start, end;

	MPI_Init(&argc, &argv);

	MPI_Comm_rank(MPI_COMM_WORLD, &proc_id);
	MPI_Comm_size(MPI_COMM_WORLD, &no_of_procs);

	//printf("No of elements: ");
	//scanf_s("%d", &no_of_elements);
	no_of_elements = 25;

	if (proc_id == MASTER)
	{
		step = no_of_elements / no_of_procs;

		for (i = 0; i < no_of_elements; i++)
			array[i] = i + 1;

		for (id = 1; id < no_of_procs; id++) {
			start = id * step + 1;
			end = (id + 1)*step;
			
			if (id == no_of_procs - 1)
			{
				end = no_of_elements - 1;
			}
			
			no_of_elem_for_child = end - start + 1;
			
			MPI_Send(&no_of_elem_for_child, 1, MPI_INT, id, 1, MPI_COMM_WORLD);
			MPI_Send(&array[start], no_of_elem_for_child, MPI_INT, id, 1, MPI_COMM_WORLD);
		}

		total_sum = 0;

		for (i = 0; i < step + 1; i++)
			total_sum += array[i];

		printf("\nPartial sum calculated by MASTER: %d\n", total_sum);

		for (id = 1; id < no_of_procs; id++) {
			MPI_Recv(&partial_sum, 1, MPI_INT, id, 1, MPI_COMM_WORLD, &status);
			total_sum += partial_sum;
		}
		
		printf("Total: %d\n", total_sum);
	}
	else 
	{
		MPI_Recv(&no_of_elem_for_child, 1, MPI_INT, MASTER, 1, MPI_COMM_WORLD, &status);
		MPI_Recv(&local_array, no_of_elem_for_child, MPI_INT, MASTER, 1, MPI_COMM_WORLD, &status);

		partial_sum = 0;

		for (i = 0; i < no_of_elem_for_child; i++)
			partial_sum += local_array[i];
			printf("Partial sum calculated by process %d : %d\n", proc_id, partial_sum);
			MPI_Send(&partial_sum, 1, MPI_INT, MASTER, 1, MPI_COMM_WORLD);
	}
	MPI_Finalize();
}
